{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ca940c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests #imports\n",
    "from bs4 import BeautifulSoup #https://realpython.com/beautiful-soup-web-scraper-python/\n",
    "import pandas as pd\n",
    "import re #https://stackoverflow.com/questions/17336943/removing-non-numeric-characters-from-a-string\n",
    "import numpy as np \n",
    "#https://medium.com/analytics-vidhya/how-to-scrape-a-table-from-website-using-python-ce90d0cfb607\n",
    "#https://www.statology.org/pandas-to-csv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0a7dcee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the soup of HTML\n",
    "def initialize(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    results = soup.find(id=\"fittPageContainer\")\n",
    "    tables = results.find_all(\"div\", class_=\"ResponsiveTable ResponsiveTable--fixed-left pt4\")\n",
    "    return results, tables\n",
    "\n",
    "#Find the name of the player\n",
    "def nameandposition(results):\n",
    "    name_and_position = results.find_all(\"div\", class_=\"PlayerHeader__Main_Aside min-w-0 flex-grow flex-basis-0\")\n",
    "    for element in name_and_position:\n",
    "        name = element.find(\"h1\", class_=\"PlayerHeader__Name\")\n",
    "        name = name.text.strip()\n",
    "        \n",
    "    for element in name_and_position:\n",
    "        pos = element.find(\"ul\", class_=\"PlayerHeader__Team_Info list flex pt1 pr4 min-w-0 flex-basis-0 flex-shrink flex-grow nowrap\")\n",
    "    numrole = pos.text.strip().split('#')[1]\n",
    "    role = ''.join(i for i in numrole if not i.isdigit())\n",
    "    return name, role\n",
    "\n",
    "def basic_data(results):\n",
    "    immutable_elements = results.find_all(\"div\", class_=\"fw-medium clr-black\")\n",
    "    HTWT = immutable_elements[0].text.strip()\n",
    "    DOB = immutable_elements[1].text.strip()\n",
    "    COLLEGE = immutable_elements[2].text.strip()\n",
    "    Draftpick = immutable_elements[3].text.strip()\n",
    "    activity_status = immutable_elements[4].text.strip()\n",
    "    \n",
    "    #Seperate Height and Weight\n",
    "    x = HTWT.split(', ')\n",
    "    ht = x[0]\n",
    "    wt = x[1]\n",
    "    #process height\n",
    "    y = ht.split(' ')\n",
    "    ft = y[0]\n",
    "    inch = y[1]\n",
    "    ft = int(re.sub('[^0-9]','', ft))\n",
    "    inch = int(re.sub('[^0-9]','', inch))\n",
    "    height = ((12*ft)+inch)\n",
    "    #process weight\n",
    "    weight = int(re.sub('[^0-9]','', wt))\n",
    "    \n",
    "    #process DOB\n",
    "    x = DOB.split(' (')\n",
    "    DOB = x[0]\n",
    "    y = DOB.split('/')\n",
    "    DOB = int(re.sub('[^0-9]','', y[2]))\n",
    "    \n",
    "    #process Draft pick data\n",
    "    x = Draftpick.split(': ')\n",
    "    draftyear = int(re.sub('[^0-9]','', x[0]))\n",
    "    y = x[1].split(', Pk ')\n",
    "    draftround = int(re.sub('[^0-9]','', y[0]))\n",
    "    z = y[1].split(' ')\n",
    "    draftpick = int(re.sub('[^0-9]','', z[0]))\n",
    "    draftteam = z[1]\n",
    "    \n",
    "    return height, weight, DOB, COLLEGE, draftyear, draftround, draftpick, draftteam, activity_status\n",
    "\n",
    "def build_basedata(results):\n",
    "    name, position = nameandposition(results)\n",
    "    height, weight, DOB, COLLEGE, draftyear, draftround, draftpick, draftteam, activity_status = basic_data(results)\n",
    "    data = {\n",
    "        'name':[name],\n",
    "        'position':[position],\n",
    "        'height (inches)':[height],\n",
    "        'weight (pounds)':[weight],\n",
    "        'DOB':[DOB],\n",
    "        'COLLEGE':[COLLEGE],\n",
    "        'draftyear':[draftyear],\n",
    "        'draftround':[draftround],\n",
    "        'draftpick':[draftpick],\n",
    "        'draftteam':[draftteam],\n",
    "        'activity_status':[activity_status]}\n",
    "    dataframe = pd.DataFrame(data)\n",
    "    return dataframe\n",
    "\n",
    "def maketable(data, statname):\n",
    "    #Find the first part of the table from the html\n",
    "    data1 = data.find(\"table\", class_=\"Table Table--align-right Table--fixed Table--fixed-left\")\n",
    "    \n",
    "    # Obtain every title of columns with tag <th>\n",
    "    headers = []\n",
    "    for i in data1.find_all(\"th\"):\n",
    "        title = i.text\n",
    "        headers.append(title)\n",
    "    \n",
    "    # Create a dataframe\n",
    "    data1data = pd.DataFrame(columns = headers)\n",
    "\n",
    "    # Create a for loop to fill table\n",
    "    for j in data1.find_all(\"tr\")[1:]:\n",
    "        row_data = j.find_all(\"td\")\n",
    "        row = [i.text for i in row_data]\n",
    "        length = len(data1data)\n",
    "        data1data.loc[length] = row\n",
    "    \n",
    "    #find the second part of the table from the html\n",
    "    data2 = data.find(\"table\", class_=\"Table Table--align-right\")\n",
    "    \n",
    "    # Obtain every title of columns with tag <th>\n",
    "    headers = []\n",
    "    for i in data2.find_all(\"th\"):\n",
    "        title = i.text\n",
    "        headers.append(title)\n",
    "    \n",
    "    #Add name tag to all headers\n",
    "    append_str = statname\n",
    "    headers = [append_str + sub for sub in headers]\n",
    "    \n",
    "    # Create a dataframe\n",
    "    data2data = pd.DataFrame(columns = headers)\n",
    "    \n",
    "    # Create a for loop to fill mydata\n",
    "    for j in data2.find_all(\"tr\")[1:]:\n",
    "        row_data = j.find_all(\"td\")\n",
    "        row = [i.text for i in row_data]\n",
    "        length = len(data2data)\n",
    "        data2data.loc[length] = row\n",
    "        \n",
    "    datadata = pd.concat([data1data,data2data], axis = 1)\n",
    "    datadata.drop(datadata.tail(1).index,inplace=True)\n",
    "    return datadata\n",
    "\n",
    "def makereturningtable(data):\n",
    "    \n",
    "    data1headers = data.find(\"table\", class_=\"Table Table--align-right Table--fixed Table--fixed-left\")\n",
    "    \n",
    "    headers = []\n",
    "    for i in data1headers.find_all(\"th\"):\n",
    "        title = i.text\n",
    "        headers.append(title)\n",
    "        \n",
    "    data1data = pd.DataFrame(columns = headers[1:])\n",
    "    \n",
    "    data1 = data.find(\"tbody\", class_=\"Table__TBODY\")\n",
    "    \n",
    "    for j in data1.find_all(\"tr\")[0:]:\n",
    "        row_data = j.find_all(\"td\")\n",
    "        row = [i.text for i in row_data]\n",
    "        length = len(data1data)+2\n",
    "        data1data.loc[length] = row\n",
    "        \n",
    "        \n",
    "    data1data = data1data.reset_index()\n",
    "    del data1data['index']\n",
    "\n",
    "    data2headers = data.find(\"table\", class_=\"Table Table--align-right\")\n",
    "    headers = []\n",
    "    for i in data2headers.find_all(\"th\"):\n",
    "        title = i.text\n",
    "        headers.append(title)\n",
    "    append_str = \"returning: \"\n",
    "    \n",
    "    for i in range(0, 8):\n",
    "        headers[i] = \"PUNTS: \" + headers[i]\n",
    "    for i in range(8, 13):\n",
    "        headers[i] = \"KICKOFFS: \" + headers[i]\n",
    "    \n",
    "    headers = [append_str + sub for sub in headers]\n",
    "    \n",
    "    data2data = pd.DataFrame(columns = headers[2:])\n",
    "    \n",
    "    data2 = data.find_all(\"tbody\", class_=\"Table__TBODY\")[1]\n",
    "    for j in data2.find_all(\"tr\")[0:]:\n",
    "        row_data = j.find_all(\"td\")\n",
    "        row = [i.text for i in row_data]\n",
    "        length = len(data2data)\n",
    "        data2data.loc[length] = row\n",
    "\n",
    "    \n",
    "    datadata = pd.concat([data1data,data2data], axis = 1)\n",
    "    datadata.drop(datadata.tail(1).index,inplace=True)\n",
    "    return datadata\n",
    "\n",
    "def bulkdata(results, tables):\n",
    "    returnlist = []\n",
    "    for i in range(0,len(tables)):\n",
    "        if \"Passing\" in tables[i].text:\n",
    "            passingdat = maketable(tables[i], \"Passing: \")\n",
    "            returnlist.append(passingdat)\n",
    "        elif \"Rushing\" in tables[i].text:\n",
    "            rushingdat = maketable(tables[i], \"Rushing: \")\n",
    "            returnlist.append(rushingdat)\n",
    "        elif \"Receiving\" in tables[i].text:\n",
    "            receivingdat = maketable(tables[i], \"Receiving: \")\n",
    "            returnlist.append(receivingdat)\n",
    "        elif \"Returning\" in tables[i].text:\n",
    "            returningdat = makereturningtable(tables[i])\n",
    "            returnlist.append(returningdat)\n",
    "        elif \"Defensive\" in tables[i].text:\n",
    "            defensivedat = maketable(tables[i], \"Defensive: \")\n",
    "            returnlist.append(defensivedat)\n",
    "        elif \"Scoring\" in tables[i].text:\n",
    "            scoringdat = maketable(tables[i], \"Scoring: \")\n",
    "            returnlist.append(scoringdat)\n",
    "    return returnlist\n",
    "\n",
    "def combinedata(a, basedata):\n",
    "    length = len(a)\n",
    "    finaldata = pd.merge(a[0], a[1], on=['season','Team'], how = 'outer')\n",
    "    for i in range(2,length):\n",
    "        finaldata = pd.merge(finaldata, a[i], on=['season','Team'], how = 'outer')\n",
    "        \n",
    "    rows = len(finaldata.index)\n",
    "    \n",
    "    #source: https://stackoverflow.com/questions/50788508/how-can-i-replicate-rows-in-pandas\n",
    "    addition = basedata\n",
    "    addition = pd.DataFrame(np.repeat(addition.values, rows, axis=0))\n",
    "    addition.columns = basedata.columns\n",
    "    \n",
    "    finaldata = pd.concat([addition,finaldata], axis = 1)\n",
    "    \n",
    "    finaldata = finaldata.apply(pd.to_numeric, errors='ignore')\n",
    "    #add age, source:https://towardsdatascience.com/create-new-column-based-on-other-columns-pandas-5586d87de73d\n",
    "    finaldata['age'] = finaldata.apply(lambda row: row.season - row.DOB, axis=1)\n",
    "    \n",
    "    #convert all numerical cells to int or float\n",
    "    \n",
    "    return finaldata\n",
    "\n",
    "def fantasy_add(dataframe1, url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    results = soup.find('div', class_=\"Page-shell\")\n",
    "    table = results.find(\"table\", class_=\"TableBase-table\")\n",
    "    \n",
    "    \n",
    "    dataheaders = table.find(\"tr\", class_=\"TableBase-headTr\")\n",
    "    #headers = []\n",
    "    headers = ['season','team','games','fantasy points', 'fantasy points per game', 'rushing attempts', 'rushing yards', 'avg yards per rush', 'rushing touchdowns', 'longest rush', 'rushing first downs', 'recieving targets', 'receptions','recieving yards', 'average yards per reception', 'recieving touchdowns', 'longest reception','recieving first downs','total fumbles','fumbles lost']\n",
    "    #for i in dataheaders.find_all(\"th\"):\n",
    "        #title = i.text\n",
    "        #headers.append(title)\n",
    "\n",
    "    tabledata = pd.DataFrame(columns = headers)\n",
    "    \n",
    "    data = table.find(\"tbody\")\n",
    "    \n",
    "    for j in data.find_all(\"tr\")[0:]:\n",
    "        row_data = j.find_all(\"td\")\n",
    "        row = [i.text for i in row_data]\n",
    "        #print(len(row))\n",
    "        length = len(headers)\n",
    "        #print(length)\n",
    "        tabledata.loc[length] = row\n",
    "        #tabledata=tabledata.append(row)\n",
    "\n",
    "    tabledata = tabledata.replace(r'\\n',' ', regex=True) \n",
    "    \n",
    "    fantasydata = tabledata[['season','fantasy points','fantasy points per game']]\n",
    "    fantasydata = fantasydata.drop([0, 1, 2])\n",
    "    fantasydata.drop(fantasydata.tail(1).index,inplace=True)\n",
    "    \n",
    "    fantasydata = fantasydata.apply(pd.to_numeric, errors='ignore')\n",
    "    dataframe1 = dataframe1.apply(pd.to_numeric, errors='ignore')\n",
    "    \n",
    "    finaldata = pd.merge(dataframe1, fantasydata, on=['season'], how = 'outer')\n",
    "    \n",
    "    return finaldata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "67b392a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fullscrape(espn, cbs):\n",
    "    results, tables = initialize(espn)\n",
    "    name, position = nameandposition(results)\n",
    "    height, weight, DOB, COLLEGE, draftyear, draftround, draftpick, draftteam, activity_status = basic_data(results)\n",
    "    basedata = build_basedata(results)\n",
    "    a = bulkdata(results,tables)\n",
    "    df = combinedata(a, basedata)\n",
    "    df1 = fantasy_add(df, cbs)\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d52d5fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = fullscrape(\"https://www.espn.com/nfl/player/stats/_/id/4040761/devin-singletary\", \"https://www.cbssports.com/nfl/players/2241251/devin-singletary/career-stats/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "78c419ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # https://stackoverflow.com/questions/19124601/pretty-print-an-entire-pandas-series-dataframe\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2faba6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test 2\n",
    "#taiwan_jones = fullscrape(\"https://www.espn.com/nfl/player/stats/_/id/14167/taiwan-jones\", \"https://www.cbssports.com/nfl/players/1682469/taiwan-jones/career-stats/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c35a1bc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#with pd.option_context('display.max_rows', None, 'display.max_columns', None):  # https://stackoverflow.com/questions/19124601/pretty-print-an-entire-pandas-series-dataframe\n",
    " #   print(taiwan_jones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a6f8ed31",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot set a row with mismatched columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [96]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m espn \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.espn.com/nfl/player/stats/_/id/3918298/josh-allen\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      2\u001b[0m cbs \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.cbssports.com/nfl/players/2181054/josh-allen/career-stats/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mfullscrape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mespn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m display(df)\n",
      "Input \u001b[1;32mIn [91]\u001b[0m, in \u001b[0;36mfullscrape\u001b[1;34m(espn, cbs)\u001b[0m\n\u001b[0;32m      6\u001b[0m a \u001b[38;5;241m=\u001b[39m bulkdata(results,tables)\n\u001b[0;32m      7\u001b[0m df \u001b[38;5;241m=\u001b[39m combinedata(a, basedata)\n\u001b[1;32m----> 8\u001b[0m df1 \u001b[38;5;241m=\u001b[39m \u001b[43mfantasy_add\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df1\n",
      "Input \u001b[1;32mIn [90]\u001b[0m, in \u001b[0;36mfantasy_add\u001b[1;34m(dataframe1, url)\u001b[0m\n\u001b[0;32m    245\u001b[0m     length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(headers)\n\u001b[0;32m    246\u001b[0m     \u001b[38;5;66;03m#print(length)\u001b[39;00m\n\u001b[1;32m--> 247\u001b[0m     tabledata\u001b[38;5;241m.\u001b[39mloc[length] \u001b[38;5;241m=\u001b[39m row\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;66;03m#tabledata=tabledata.append(row)\u001b[39;00m\n\u001b[0;32m    250\u001b[0m tabledata \u001b[38;5;241m=\u001b[39m tabledata\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:716\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[0;32m    715\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[1;32m--> 716\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1682\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[1;34m(self, indexer, value, name)\u001b[0m\n\u001b[0;32m   1679\u001b[0m     indexer, missing \u001b[38;5;241m=\u001b[39m convert_missing_indexer(indexer)\n\u001b[0;32m   1681\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m missing:\n\u001b[1;32m-> 1682\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1683\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m   1685\u001b[0m \u001b[38;5;66;03m# align and set the values\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1998\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_missing\u001b[1;34m(self, indexer, value)\u001b[0m\n\u001b[0;32m   1995\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_list_like_indexer(value):\n\u001b[0;32m   1996\u001b[0m         \u001b[38;5;66;03m# must have conforming columns\u001b[39;00m\n\u001b[0;32m   1997\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns):\n\u001b[1;32m-> 1998\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot set a row with mismatched columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   2000\u001b[0m     value \u001b[38;5;241m=\u001b[39m Series(value, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mcolumns, name\u001b[38;5;241m=\u001b[39mindexer)\n\u001b[0;32m   2002\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj):\n\u001b[0;32m   2003\u001b[0m     \u001b[38;5;66;03m# We will ignore the existing dtypes instead of using\u001b[39;00m\n\u001b[0;32m   2004\u001b[0m     \u001b[38;5;66;03m#  internals.concat logic\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: cannot set a row with mismatched columns"
     ]
    }
   ],
   "source": [
    "espn = \"https://www.espn.com/nfl/player/stats/_/id/3918298/josh-allen\"\n",
    "cbs = \"https://www.cbssports.com/nfl/players/2181054/josh-allen/career-stats/\"\n",
    "df = fullscrape(espn, cbs)\n",
    "display(df)\n",
    "#df.to_csv(r'C:\\Users\\rghan\\Python Stuff\\Fantasy-Football-Project\\Player Stats\\josh_allen.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecd7929",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
